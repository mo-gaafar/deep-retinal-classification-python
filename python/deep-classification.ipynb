{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic Classification of Bright Retinal Lesions via Deep Network Features\n",
    "**Original Paper Authors**\n",
    "Ibrahim Sadeka,b,*, Mohamed Elawadyc,e, Abd El Rahman Shabayekd,e\n",
    "\n",
    "### A reimplementation of the paper using python instead of matlab\n",
    "Under supervision of Dr. Ibrahim Sadek, ibrahim.sadek@ipal.cnrs.fr\n",
    "\n",
    "**Reimplementation Authors**\n",
    "| **Name** | **Email** |\n",
    "| --- | --- |\n",
    "|[Mohamed Gaafer](github.com/mo-gaafar)| mohamed_gaafer@ieee.org|\n",
    "|[Zeyad Mansour](github.com/ZeyadAlo) | zeyadmansour2@gmail.com |\n",
    "|[Abdullah Saeed](github.com/abdullahsaeed10) ||\n",
    "|[Maryam Moataz](github.com/maryamoataz) | maryam.fathy01@eng-st.cu.edu.eg|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from PIL import Image\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, recall_score, f1_score, accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Structure\n",
    "These are the main steps of the code:\n",
    "1. Image Loading\n",
    "2. Network Configuration\n",
    "3. Data Preprocessing\n",
    "4. CNN Feature Extraction using GoogleNet\n",
    "5. Load pretrained SVM Model and Predict based on CNN Features\n",
    "\n",
    "\n",
    "## 1. Image Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "971ca8e9430d41b8a55b45877702fd25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='../input', description='Directory:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aeb8d183ca142d4b002fc475c137699",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Files:', options=(), value=None)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "import os\n",
    "\n",
    "directory = \"\"\n",
    "\n",
    "# Function to display image files in a directory\n",
    "def display_files(directory):\n",
    "    file_list = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.png', '.jpg', '.jpeg', '.gif')): \n",
    "                file_list.append(os.path.join(root, file))\n",
    "    file_widget.options = file_list\n",
    "\n",
    "# Define the directory widget\n",
    "directory_widget = widgets.Text(value='../input', description='Directory:')\n",
    "display(directory_widget)\n",
    "\n",
    "# Define the file selection widget\n",
    "file_widget = widgets.Dropdown(options=[], description='Files:')\n",
    "display(file_widget)\n",
    "\n",
    "# Define the callback function for directory changes\n",
    "def directory_changed(change):\n",
    "    directory = change['new']\n",
    "    display_files(directory)\n",
    "    print(directory)\n",
    "\n",
    "# Link the directory widget to the callback function\n",
    "directory_widget.observe(directory_changed, names='value')\n",
    "\n",
    "# Initialize the file list\n",
    "display_files(directory_widget.value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directory\n",
      "../input/drusen/sample3.jpg\n"
     ]
    }
   ],
   "source": [
    "print(\"directory\")\n",
    "print(file_widget.value)\n",
    "\n",
    "im = Image.open(file_widget.value)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Network Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ba3da1f2ed640c28c4582e886612c24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Layers:', options=('input_10', 'block1_conv1', 'block1_conv2', 'block1_pool', 'block2_coâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#googlenet\n",
    "# model_googlenet = keras.applications.inception_v3.InceptionV3(weights='imagenet')\n",
    "model_googlenet = keras.applications.VGG16(weights='imagenet'\n",
    "                                          , include_top=False\n",
    "                                          , input_shape=(224, 224, 3)\n",
    "                                          , classes=1000)\n",
    "#select and display the layer from ipywidget dropdown\n",
    "layers_list = [layer.name for layer in model_googlenet.layers]\n",
    "layer_widget = widgets.Dropdown(options=layers_list, description='Layers:')\n",
    "display(layer_widget)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=model_googlenet.input, outputs=model_googlenet.get_layer(layer_widget.value).output)\n",
    "# model_googlenet.summary()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32md:\\senior 1\\spring\\image\\deep-retinal-classification-python\\python\\deep-classification.ipynb Cell 10\u001b[0m in \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/senior%201/spring/image/deep-retinal-classification-python/python/deep-classification.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Data Pre-processing\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/senior%201/spring/image/deep-retinal-classification-python/python/deep-classification.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m image\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/senior%201/spring/image/deep-retinal-classification-python/python/deep-classification.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapplications\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvgg16\u001b[39;00m \u001b[39mimport\u001b[39;00m preprocess_input, decode_predictions\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/senior%201/spring/image/deep-retinal-classification-python/python/deep-classification.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# Data Pre-processing\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "\n",
    "img = image.load_img(file_widget.value, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. CNN Feature Extraction using GoogleNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 286ms/step\n",
      "(1, 14, 14, 512)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x10d7af5b0>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CNN Feature Extraction using GoogleLeNet Model\n",
    "features = model.predict(x)\n",
    "print(features.shape)\n",
    "plt.imshow(features[0,:,:,0])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. SVM Prediction using CNN Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1, 3]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[97], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m features_train, features_test, labels_train, labels_test \u001b[39m=\u001b[39m train_test_split(features, labels, test_size\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m, random_state\u001b[39m=\u001b[39;49m\u001b[39m42\u001b[39;49m)\n\u001b[1;32m      3\u001b[0m \u001b[39m# Flatten the features into one-dimensional vectors\u001b[39;00m\n\u001b[1;32m      4\u001b[0m features_train \u001b[39m=\u001b[39m features_train\u001b[39m.\u001b[39mreshape(features_train\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/GitHub/deep-retinal-classification-python/.venv/lib/python3.9/site-packages/sklearn/model_selection/_split.py:2559\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2556\u001b[0m \u001b[39mif\u001b[39;00m n_arrays \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   2557\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAt least one array required as input\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 2559\u001b[0m arrays \u001b[39m=\u001b[39m indexable(\u001b[39m*\u001b[39;49marrays)\n\u001b[1;32m   2561\u001b[0m n_samples \u001b[39m=\u001b[39m _num_samples(arrays[\u001b[39m0\u001b[39m])\n\u001b[1;32m   2562\u001b[0m n_train, n_test \u001b[39m=\u001b[39m _validate_shuffle_split(\n\u001b[1;32m   2563\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[39m=\u001b[39m\u001b[39m0.25\u001b[39m\n\u001b[1;32m   2564\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/GitHub/deep-retinal-classification-python/.venv/lib/python3.9/site-packages/sklearn/utils/validation.py:443\u001b[0m, in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[1;32m    425\u001b[0m \n\u001b[1;32m    426\u001b[0m \u001b[39mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[39m    sparse matrix, or dataframe) or `None`.\u001b[39;00m\n\u001b[1;32m    440\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    442\u001b[0m result \u001b[39m=\u001b[39m [_make_indexable(X) \u001b[39mfor\u001b[39;00m X \u001b[39min\u001b[39;00m iterables]\n\u001b[0;32m--> 443\u001b[0m check_consistent_length(\u001b[39m*\u001b[39;49mresult)\n\u001b[1;32m    444\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Documents/GitHub/deep-retinal-classification-python/.venv/lib/python3.9/site-packages/sklearn/utils/validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    395\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[1;32m    396\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 397\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    398\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    399\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[1;32m    400\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1, 3]"
     ]
    }
   ],
   "source": [
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Flatten the features into one-dimensional vectors\n",
    "features_train = features_train.reshape(features_train.shape[0], -1)\n",
    "features_test = features_test.reshape(features_test.shape[0], -1)\n",
    "\n",
    "# Train an SVM classifier on the flattened features\n",
    "clf = SVC(kernel='linear', C=1.0, probability=True)\n",
    "clf.fit(features_train, labels_train)\n",
    "\n",
    "\n",
    "class_names = ['Drusen', 'Exudate', 'Normal', ...] \n",
    "predicted_class_name=[]\n",
    "# Classify the image using the SVM classifier\n",
    "for i in range(0, len(features_test)):\n",
    "    predicted_label = clf.predict(features_test)[i]\n",
    "    predicted_class_name.append(predicted_label)\n",
    "\n",
    "# Output the classification result   \n",
    "print(predicted_class_name)   \n",
    "print(labels_test)\n",
    "\n",
    "cm = confusion_matrix(labels_test, predicted_class_name)\n",
    "print(cm)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluation\n",
    "Criteria used for evaluation:\n",
    "- Sensitivity, specificity, accuracy, F-score, the area\n",
    "under the curve\n",
    "- Robustness\n",
    "- Methodology\n",
    "- Computational time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "confusion_matrix() got multiple values for argument 'labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[91], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[39mreturn\u001b[39;00m cm\n\u001b[1;32m     13\u001b[0m \u001b[39m# Calculate confusion matrix\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m cm \u001b[39m=\u001b[39m confusion_matrix(labels, predictions)\n\u001b[1;32m     16\u001b[0m \u001b[39m# Dataframe of confusion matrix\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[91], line 10\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[0;34m(labels, predictions)\u001b[0m\n\u001b[1;32m      8\u001b[0m classes \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(np\u001b[39m.\u001b[39mconcatenate((labels, predictions)))\n\u001b[1;32m      9\u001b[0m \u001b[39m# Create the confusion matrix\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m cm \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(confusion_matrix(labels, predictions, labels\u001b[39m=\u001b[39;49mclasses), index\u001b[39m=\u001b[39mclasses, columns\u001b[39m=\u001b[39mclasses)\n\u001b[1;32m     11\u001b[0m \u001b[39mreturn\u001b[39;00m cm\n",
      "\u001b[0;31mTypeError\u001b[0m: confusion_matrix() got multiple values for argument 'labels'"
     ]
    }
   ],
   "source": [
    "# # Confusion matrix plot\n",
    "# # Array of labels and predictions \"drusen, exudates, normal\"\n",
    "# labels = ['drusen', 'exudates', 'normal']\n",
    "# predictions = ['drusen', 'exudates', 'normal']\n",
    "\n",
    "# def confusion_matrix(labels, predictions):\n",
    "#     # Get number of unique classes\n",
    "#     classes = np.unique(np.concatenate((labels, predictions)))\n",
    "#     # Create the confusion matrix\n",
    "#     cm = pd.DataFrame(confusion_matrix(labels, predictions, labels=classes), index=classes, columns=classes)\n",
    "#     return cm\n",
    "\n",
    "# # Calculate confusion matrix\n",
    "# cm = confusion_matrix(labels, predictions)\n",
    "\n",
    "# # Dataframe of confusion matrix\n",
    "\n",
    "# Plot the confusion matrix\n",
    "# plot_confusion_matrix(clf, features_test, labels_test, cmap=plt.cm.Blues)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf.classes_)\n",
    "disp.plot()\n",
    "\n",
    "# Calculate the sensitivity\n",
    "sensitivity = recall_score(labels_test, predicted_class_name, average='macro')\n",
    "\n",
    "# Extract the true negatives (TN) and false positives (FP) for each class\n",
    "tn_0 = np.sum(cm[1:, 1:])  # TN for class 0\n",
    "fp_0 = np.sum(cm[1:, 0])   # FP for class 0\n",
    "tn_1 = np.sum(np.vstack((cm[0, 0], cm[2, 2])))  # TN for class 1\n",
    "fp_1 = np.sum(np.hstack((cm[0, 1:], cm[2, :2])))  # FP for class 1\n",
    "tn_2 = np.sum(cm[:2, :2])  # TN for class 2\n",
    "fp_2 = np.sum(np.hstack((cm[:2, 2], cm[2, 0:2])))  # FP for class 2\n",
    "\n",
    "# Calculate the specificity for each class\n",
    "spec_0 = tn_0 / (tn_0 + fp_0)\n",
    "spec_1 = tn_1 / (tn_1 + fp_1)\n",
    "spec_2 = tn_2 / (tn_2 + fp_2)\n",
    "\n",
    "# Calculate the accuracy score\n",
    "accuracy = accuracy_score(labels_test, predicted_class_name)\n",
    "\n",
    "# Calculate the F-score\n",
    "f_score = f1_score(labels_test, predicted_class_name, average='weighted')\n",
    "\n",
    "# Calculate the AUC score\n",
    "y_test = np.reshape(labels_test, (-1, 1))\n",
    "y_pred = np.reshape(predicted_class_name, (-1, 1))\n",
    "y_pred = normalize(y_pred, axis=1, norm='l1')\n",
    "y_test = normalize(y_test, axis=1, norm='l1')\n",
    "\n",
    "auc_score = roc_auc_score(y_test, y_pred, multi_class='ovr')\n",
    "\n",
    "print(\"Sensitivity: {:.2f}\".format(sensitivity))\n",
    "\n",
    "print(\"Specificity for class Drusen: {:.2f}\".format(spec_0))\n",
    "print(\"Specificity for class Exudate: {:.2f}\".format(spec_1))\n",
    "print(\"Specificity for class Normal: {:.2f}\".format(spec_2))\n",
    "\n",
    "print(\"Accuracy: {:.2f}\".format(accuracy))\n",
    "\n",
    "print(\"F-score: {:.2f}\".format(f_score))\n",
    "\n",
    "print(\"AUC: {:.2f}\".format(auc_score))\n",
    "\n",
    "# show the confusion matrix plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
